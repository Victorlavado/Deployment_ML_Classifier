{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap Up\n",
    "\n",
    "This last notebook in the research enviroment covers all the steps follows in the four previous notebooks and sumarizes into just one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "\n",
    "# Preprocessing and Feature engineering\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Model building\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Persist the model and the scaler\n",
    "import joblib\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Uninformative Variables\n",
    "\n",
    "In the data analysis we found out that *PassengerId, Name, Ticket and Cabin* are variable that do not provide useful information to predict the likelihood of surviving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data,\n",
    "                                                    data['Survived'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load selected features\n",
    "features = pd.read_csv('selected_features.csv', header=None)\n",
    "features = [x for x in features[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "\n",
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin       0.771044\n",
       "Embarked    0.002245\n",
       "dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a list of categorical variables:\n",
    "cat_var_na= [var for var in data.columns if data[var].dtypes == 'O' \n",
    "          and data[var].isnull().sum() > 0]\n",
    "\n",
    "data[cat_var_na].isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin       0.0\n",
       "Embarked    0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Cabin       0.0\n",
       "Embarked    0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# replace missing values with new label: \"Missing\"\n",
    "\n",
    "X_train[cat_var_na] = X_train[cat_var_na].fillna('Missing')\n",
    "X_test[cat_var_na] = X_test[cat_var_na].fillna('Missing')\n",
    "\n",
    "# check there are no missing values\n",
    "display(X_train[cat_var_na].isnull().mean())\n",
    "display(X_test[cat_var_na].isnull().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variables\n",
    "\n",
    "We will engineer missing values in numerical values, following two steps:\n",
    "\n",
    "1. add a binary missing value indicator variable\n",
    "2. replace the missing values in the original variable with the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age    0.198034\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Age    0.201117\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make a list with the numerical variables that contain missing values\n",
    "num_var_na = [\n",
    "    var for var in X.columns\n",
    "    if X_train[var].isnull().sum() > 0 and X_train[var].dtypes != 'O'\n",
    "]\n",
    "\n",
    "# print percentage of missing values per variable\n",
    "display(X_train[num_var_na].isnull().mean())\n",
    "display(X_test[num_var_na].isnull().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Age    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for var in num_var_na:\n",
    "    \n",
    "    # Compute the mode using the train set\n",
    "    mode_val = X_train[var].mode()[0]\n",
    "    \n",
    "    # add binary missing indicator in the two partitions\n",
    "    X_train[var+'_na'] = np.where(X_train[var].isnull(), 1, 0)\n",
    "    X_test[var+'_na'] = np.where(X_test[var].isnull(), 1, 0)\n",
    "    \n",
    "    # replace missing values with the training mode\n",
    "    X_train[var] = X_train[var].fillna(mode_val)\n",
    "    X_test[var] = X_test[var].fillna(mode_val)\n",
    "    \n",
    "# Check there are no missing values in both partitions\n",
    "\n",
    "display(X_train[num_var_na].isnull().sum())\n",
    "display(X_test[num_var_na].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Transformation\n",
    "\n",
    "In the data analysis notebook there were two numerical variables that are not normally distributed: *Age* and *Fare*.\n",
    "\n",
    "*Age* can be approximated to a normal distribution using a log transformation. \n",
    "\n",
    "However, *Fare* variable does not admit a log transformation, as it contains 0 and negative values. Even other transformation such as squaring the variable do not work either. We will limit ourselves to transform the *Fare* variable to a strictly null or positive variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age variable transformation\n",
    "X_train['Age'] = np.log(X_train['Age'])\n",
    "X_test['Age'] = np.log(X_test['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fare variable transformation\n",
    "X_train['Fare'] = abs(X_train['Fare'])\n",
    "X_test['Fare'] = abs(X_test['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the train set does not contain missing values in the engineered variables\n",
    "[var for var in ['Age', 'Fare'] if X_train[var].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the test set does not contain missing values in the engineered variables\n",
    "[vars for vars in ['Age', 'Fare'] if X_test[var].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Categorical Variables\n",
    "\n",
    "In this section, the categorical variables will be encoded to turn the strings into numbers. The idea is to capture the monotonic relationship between the label and the target.\n",
    "\n",
    "To achieve that, the discrete values of the categorical variables will have a lower or higher numerical value depending on how they lower or grow the likelihood of surviving. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_cat(train, test, var, target):\n",
    "    \n",
    "    # order the categories in a variable from that with the lowest\n",
    "    # surviving mean, to that with the highest\n",
    "    ordered_labels = train.groupby([var])[target].mean().sort_values().index\n",
    "    \n",
    "    # create a dictionary of ordered categories\n",
    "    ordinal_label = {k:i for i, k in enumerate(ordered_labels, 0)}\n",
    "    \n",
    "    # the dictionary replaces the categorical strings by integers\n",
    "    train[var] = train[var].map(ordinal_label)\n",
    "    test[var] = test[var].map(ordinal_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of categorical variables\n",
    "\n",
    "cat_var = [var for var in X.columns if X_train[var].dtypes == 'O']\n",
    "\n",
    "for var in cat_var:\n",
    "    transform_cat(X_train, X_test, var, 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check na in training set\n",
    "[var for var in X_train.columns if X_train[var].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check na in test set\n",
    "[var for var in X_test.columns if X_test[var].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Linear models need the features to be scaled or normalised. In this case, we will scale the features so they are all between the same minimum and maximum values. To do that we make use of Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture the target\n",
    "y_train = X_train['Survived']\n",
    "y_test = X_test['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the with only the selected features\n",
    "scaler.fit(X_train[features])\n",
    "\n",
    "# Persis the scaler for future use\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Transform the partitions\n",
    "X_train = scaler.transform(X_train[features])\n",
    "X_test = scaler.transform(X_test[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "As a rule of thum you do not include feature selection stage into your production code as it has some drawbacks. So, even if we perform the feature selection into the the previous notebook, here we will not show it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regressor.pkl']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the model\n",
    "clf = LogisticRegression(random_state=0)\n",
    "\n",
    "# train the model \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Persist the model for future use\n",
    "joblib.dump(clf, 'logistic_regressor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain predictions\n",
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       110\n",
      "           1       0.73      0.74      0.73        69\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.78      0.78      0.78       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n",
      "Confusion Matrix\n",
      " [[91 19]\n",
      " [18 51]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with classification report\n",
    "# and confusion matrix\n",
    "\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "print('Confusion Matrix\\n', cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
